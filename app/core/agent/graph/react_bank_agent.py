from collections import defaultdict
from typing import Dict, Any, List, Tuple, TypedDict, Optional
import pandas as pd
from langgraph.graph import StateGraph
from sqlalchemy.engine.create import create_engine
from sqlalchemy.pool.impl import QueuePool
from datetime import datetime, timedelta
from app.core.agent.graph.sql_graph import db_uri
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

engine = create_engine(
    db_uri,
    poolclass=QueuePool,  # ä½¿ç”¨é˜Ÿåˆ—æ± ï¼ˆé»˜è®¤ï¼‰
    pool_size=10,  # è¿æ¥æ± å¤§å°
    max_overflow=20,  # æœ€å¤§æº¢å‡ºè¿æ¥
    pool_timeout=30,  # è·å–è¿æ¥è¶…æ—¶æ—¶é—´
    pool_pre_ping=True,  # é¢„å…ˆæ£€æŸ¥è¿æ¥æœ‰æ•ˆæ€§
    pool_recycle=3600,  # è¿æ¥å›æ”¶æ—¶é—´ï¼ˆé¿å…æ•°æ®åº“æ–­å¼€ï¼‰
    echo=False  # è®¾ä¸ºTrueå¯æŸ¥çœ‹SQLæ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
)
DATE_FMT = "%Y%m%d"
START_DT = "20250601"
END_DT = "20250610"


class PandasSQLQueryTool:
    def __init__(self, engine):
        self.engine = engine

    def invoke(self, query: str, params: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›å­—å…¸åˆ—è¡¨
        æ”¯æŒå‚æ•°åŒ–æŸ¥è¯¢ï¼Œé˜²æ­¢SQLæ³¨å…¥
        """
        try:
            with self.engine.connect() as conn:
                result = pd.read_sql(query, conn, params=params)  # ç›´æ¥æ‰§è¡ŒSQLï¼Œæ— å‚æ•°
                return result.to_dict('records')
        except Exception as e:
            logging.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
            logging.error(f"SQL: {query}")
            return []


def load_ccy_mapping():
    """åŠ è½½å¸ç§æ˜ å°„è¡¨åˆ°å†…å­˜"""

    sql = "SELECT ccy_int, ccy_symb FROM ccy_mapping"
    results = execute_query_tool.invoke(sql)
    _CCY_MAPPING = {
        row['ccy_symb']: row['ccy_int']  # symb -> int
        for row in results
    }
    return _CCY_MAPPING


def parse_dt(dt: str) -> datetime:
    try:
        return datetime.strptime(dt, DATE_FMT)
    except ValueError as e:
        logging.error(f"Error: æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œæ— æ³•å°† '{dt}' è½¬æ¢ä¸ºæ—¥æœŸã€‚")
        raise e  # ç»§ç»­æŠ›å‡ºå¼‚å¸¸


# ä½¿ç”¨æ–¹å¼ç›¸åŒ
execute_query_tool = PandasSQLQueryTool(engine)


def classify_errors(records: List[Dict[str, Any]]) -> Dict[str, List[Any]]:
    from datetime import timedelta

    date_set = set()
    dt_start = parse_dt(START_DT)
    dt_end = parse_dt(END_DT)
    for d in range((dt_end - dt_start).days + 1):
        date_set.add((dt_start + timedelta(days=d)).strftime(DATE_FMT))

    bucket = defaultdict(list)
    for r in records:
        key = (r['org_num'], r['sbj_num'], r['ccy'])
        bucket[key].append(r)

    type1, type2, type3 = [], [], []

    for key, rows in bucket.items():
        # ---------- é¢„å¤„ç† ----------
        rows.sort(key=lambda x: x['dt'])
        exist_dates = {r['dt'] for r in rows}
        full_period = (exist_dates == date_set)  # æ˜¯å¦ 10 å¤©å…¨é‡
        diffs = [float(r['tot_mint_dif']) for r in rows]
        non_zero_count = sum(1 for d in diffs if d != 0)  # ä¸å¹³è®°å½•æ¡æ•°

        # ---------- Type1ï¼šåå¤©å…¨åœ¨ + å·®é¢æ’å®š ----------
        if full_period and len(set(diffs)) == 1:
            rows[0]['is_first'] = True
            type1.append(rows[1])
            continue

        # ---------- Type3ï¼šä¸”éå…¨é‡ ----------
        if (
                not full_period
                and non_zero_count < 10
                and non_zero_count > 0
        ):
            first_nz = next(i for i, d in enumerate(diffs) if d != 0)
            last_nz = len(diffs) - 1 - next(i for i, d in enumerate(reversed(diffs)) if d != 0)
            rows[0]['zero_span'] = {'start': rows[first_nz]['dt'],
                                    'end': rows[last_nz]['dt']}
            type3.append(rows[0])
            continue

        # ---------- Type2ï¼šå…¶ä½™å‡ºç°â‰¥2ç§å·®é¢çš„æƒ…å†µ ----------
        change_list, change_dates = [], []
        for i, d in enumerate(diffs):
            if i == 0 or d != diffs[i - 1]:
                change_list.append(d)
                change_dates.append(rows[i]['dt'])
        if len(change_list) >= 2:
            rows[0]['change_list'] = change_list
            rows[0]['change_dates'] = change_dates
            type2.append(rows[0])

    return {'type1': type1, 'type2': type2, 'type3': type3}


class OutputState(TypedDict):
    discrepancies: List[Dict[str, Any]]
    classes: Dict[str, List[Dict[str, Any]]]
    results: List[Dict[str, Any]]
    summary: Dict[str, Any]  # å»ºè®®ä¿ç•™ summaryï¼Œå¯¹ä¸»æ™ºèƒ½ä½“æœ‰ç”¨


# -------- State --------
class AgentState(TypedDict, total=False):
    discrepancies: List[Dict[str, Any]]  # åŸå§‹ä¸å¹³æ˜ç»†
    classes: Dict[str, List[Dict[str, Any]]]  # type1/type2/type3
    current_type_index: Dict[str, int]  # {"type1": 0, "type2": 0, "type3": 0}
    current_date_index: int  # å¯¹äº type2ï¼Œå½“å‰å¤„ç†åˆ° change_dates çš„ç¬¬å‡ ä¸ªæ—¥æœŸ
    current_record: Dict[str, Any]  # å½“å‰å¤„ç†çš„åˆ†ç±»è®°å½•
    current_target: Tuple[str, str, str, str]  # å½“å‰å¤„ç†ç»„ (org, sbj, ccy, dt)
    current_type: str  # å½“å‰å¤„ç†çš„ç±»å‹
    has_more: bool
    history: Dict[str, Any]
    individual: Dict[str, Any]
    per_account: List[Dict[str, Any]]
    results: List[Dict[str, Any]]  # ç´¯è®¡å„ç»„ç»“æœ
    summary: Dict[str, Any]
    red_blue_cancellations: List[Dict[str, Any]]  # æ–°å¢ï¼šç”¨äºå­˜å‚¨å†²é”€å‡­è¯æ£€æŸ¥ç»“æœ


# -------- Helpers (å‚æ•°åŒ–ç‰ˆæœ¬ SQLï¼Œé¿å…ç¡¬ç¼–ç ) --------
def _print_classification_analysis(classes: Dict[str, List[Dict[str, Any]]], discrepancies: List[Dict[str, Any]]):
    """
    æ‰“å°ä¸‰ç±»é”™è¯¯çš„åˆ†ç±»ç»“æœå’Œåˆ†æåŸå› 
    """
    logging.info("\n" + "=" * 80)
    logging.info("ã€é”™è¯¯åˆ†ç±»åˆ†ææŠ¥å‘Šã€‘")
    logging.info("=" * 80)

    total_records = len(discrepancies)
    type1_records = classes.get("type1", [])
    type2_records = classes.get("type2", [])
    type3_records = classes.get("type3", [])

    logging.info(f"\næ€»è®¡å‘ç° {total_records} æ¡ä¸å¹³è®°å½•ï¼Œåˆ†ç±»å¦‚ä¸‹ï¼š")
    logging.info(f"  - Type1 (æ’å®šå·®é¢): {len(type1_records)} ç»„")
    logging.info(f"  - Type2 (å·®é¢å˜åŒ–): {len(type2_records)} ç»„")
    logging.info(f"  - Type3 (å·®é¢å½’é›¶): {len(type3_records)} ç»„")

    # åˆ†æ Type1
    if type1_records:
        logging.info("\nã€Type1 - æ’å®šå·®é¢é”™è¯¯ã€‘")
        logging.info(
            "åˆ†æåŸå› ï¼š6æœˆ1æ—¥èµ·æ€»è´¦æˆ·ä¸åˆ†æˆ·åˆè®¡å·®é¢æ’å®šï¼Œä¸šåŠ¡æœŸé—´åˆ†æˆ·/æ€»è´¦åŒæ­¥å˜åŠ¨ã€‚è¯¥æ€»åˆ†ä¸å¹³å‘ç”Ÿåœ¨6æœˆ1æ—¥ä¹‹å‰ï¼Œå»ºè®®æ‚¨å¾€6æœˆ1æ—¥å‰è¿½æº¯åŸå› ã€‚")
        logging.info("åˆ¤æ–­æ ‡å‡†ï¼š")
        logging.info("  1. è¯¥ç»„(org_num, sbj_num, ccy)åœ¨æŸ¥è¯¢æœŸé—´å†…æ‰€æœ‰æ—¥æœŸéƒ½æœ‰è®°å½•")
        logging.info("  2. æ‰€æœ‰æ—¥æœŸçš„ tot_mint_dif å€¼å®Œå…¨ç›¸åŒï¼ˆæ’å®šå·®é¢ï¼‰")
        logging.info("  3. è¯´æ˜ï¼šå¯èƒ½å­˜åœ¨ç³»ç»Ÿæ€§çš„ä½™é¢è®¡ç®—é”™è¯¯æˆ–åˆå§‹ä½™é¢è®¾ç½®é—®é¢˜")
        logging.info(f"\nå…± {len(type1_records)} ç»„ï¼Œè¯¦æƒ…ï¼š")
        for idx, record in enumerate(type1_records, 1):
            logging.info(f"  [{idx}] æœºæ„: {record.get('org_num')}, ç§‘ç›®: {record.get('sbj_num')}, "
                         f"å¸ç§: {record.get('ccy')}, å·®é¢: {record.get('tot_mint_dif')}")

    # åˆ†æ Type2
    if type2_records:
        logging.info("\nã€Type2 - å·®é¢å˜åŒ–é”™è¯¯ã€‘")
        logging.info(
            "åˆ†æåŸå› ï¼š6æœˆ1æ—¥èµ·æ€»è´¦æˆ·ä¸åˆ†æˆ·åˆè®¡äº§ç”Ÿå·®é¢ä¸å›ºå®šï¼Œä¸šåŠ¡æœŸé—´åˆ†æˆ·/æ€»è´¦ä¸åŒæ­¥å˜åŠ¨ã€‚è¯¥æ€»åˆ†ä¸å¹³å‘ç”Ÿåœ¨6æœˆ1æ—¥ä¹‹å‰ï¼ŒåŒæ—¶ä¸­é—´åˆå‘ç”Ÿäº†æ–°çš„é”™è¯¯ï¼Œå»ºè®®æ‚¨å¯¹è¯¥è´¦æˆ·çš„ç›¸å…³æƒ…å†µè¿›è¡Œå…·ä½“åˆ†æã€‚")
        logging.info("åˆ¤æ–­æ ‡å‡†ï¼š")
        logging.info("  1. åœ¨æŸ¥è¯¢æœŸé—´å†…ï¼Œè¯¥ç»„çš„ tot_mint_dif å€¼å‘ç”Ÿäº†è‡³å°‘ä¸€æ¬¡å˜åŒ–")
        logging.info("  2. å­˜åœ¨å¤šä¸ªä¸åŒçš„å·®é¢å€¼ï¼ˆchange_list é•¿åº¦ â‰¥ 2ï¼‰")
        logging.info("  3. è¯´æ˜ï¼šå¯èƒ½åœ¨ç‰¹å®šæ—¥æœŸå‘ç”Ÿäº†äº¤æ˜“æˆ–è°ƒæ•´ï¼Œå¯¼è‡´å·®é¢å‘ç”Ÿå˜åŒ–")
        logging.info(f"\nå…± {len(type2_records)} ç»„ï¼Œè¯¦æƒ…ï¼š")
        for idx, record in enumerate(type2_records, 1):
            change_list = record.get('change_list', [])
            change_dates = record.get('change_dates', [])
            logging.info(f"  [{idx}] æœºæ„: {record.get('org_num')}, ç§‘ç›®: {record.get('sbj_num')}, "
                         f"å¸ç§: {record.get('ccy')}")
            logging.info(f"      å˜åŒ–ç‚¹: {len(change_list)} ä¸ªï¼Œå·®é¢å€¼: {change_list}")
            logging.info(f"      å˜åŒ–æ—¥æœŸ: {change_dates}")

    # åˆ†æ Type3
    if type3_records:
        logging.info("\nã€Type3 - å·®é¢å½’é›¶é”™è¯¯ã€‘")
        logging.info(
            "åˆ†æåŸå› ï¼šè´¦æˆ·éƒ¨åˆ†å¤©æ•°æ€»åˆ†å¹³è¡¡ï¼Œéƒ¨åˆ†å¤©æ•°æ€»åˆ†ä¸å¹³ã€‚å»ºè®®å€ŸåŠ©å¹³è¡¡æ³•åˆ™â€œå½“å¤©ä½™é¢=ä¸Šä¸€å¤©ä½™é¢Â±å€Ÿæ–¹å‘ç”Ÿé¢Â±è´·æ–¹å‘ç”Ÿé¢â€è¿›è¡Œè®¡ç®—æ‰¾åˆ°é”™è¯¯")
        logging.info("åˆ¤æ–­æ ‡å‡†ï¼š")
        logging.info("  1. è¯¥ç»„åœ¨æŸ¥è¯¢æœŸé—´å†…ä¸æ˜¯æ‰€æœ‰æ—¥æœŸéƒ½æœ‰è®°å½•ï¼ˆéå…¨é‡ï¼‰")
        logging.info("  2. ä¸å¹³è®°å½•æ•°å°‘äºæ€»å¤©æ•°ï¼Œä½†å¤§äº0")
        logging.info("  3. å­˜åœ¨ä¸€ä¸ªæ—¥æœŸèŒƒå›´ï¼ˆzero_spanï¼‰ï¼Œåœ¨è¿™ä¸ªèŒƒå›´å†…å·®é¢ä»éé›¶å˜ä¸ºé›¶")
        logging.info("  4. è¯´æ˜ï¼šå¯èƒ½åœ¨æŸæ®µæ—¶é—´å†…å‘ç”Ÿäº†é”™è¯¯ï¼Œä¹‹åè¢«çº æ­£æˆ–è‡ªåŠ¨å½’é›¶")
        logging.info(f"\nå…± {len(type3_records)} ç»„ï¼Œè¯¦æƒ…ï¼š")
        for idx, record in enumerate(type3_records, 1):
            zero_span = record.get('zero_span', {})
            logging.info(f"  [{idx}] æœºæ„: {record.get('org_num')}, ç§‘ç›®: {record.get('sbj_num')}, "
                         f"å¸ç§: {record.get('ccy')}")
            if zero_span:
                logging.info(f"      å¼‚å¸¸æ—¥æœŸèŒƒå›´: {zero_span.get('start')} è‡³ {zero_span.get('end')}")

    logging.info("\n" + "=" * 80)
    logging.info("å¼€å§‹é€ç»„éªŒè¯...")


def _print_account_result(state: AgentState):
    """
    æ‰“å°æ¯ä¸ªè´¦æˆ·å¤„ç†å®Œæˆåçš„ç»“æœï¼ŒåŒ…æ‹¬é”™è¯¯åŸå› å’Œå¯ç–‘è®°å½•
    """
    org, sbj, ccy, acg_dt = state.get("current_target", ("", "", "", ""))
    current_type = state.get("current_type", "unknown")
    record = state.get("current_record", {})
    history = state.get("history", {})
    individual = state.get("individual", {})
    per_account = state.get("per_account", [])

    logging.info("\n" + "-" * 80)
    logging.info(f"ã€å¤„ç†å®Œæˆ - {current_type.upper()}ã€‘")
    logging.info("-" * 80)
    logging.info(f"æœºæ„: {org}, ç§‘ç›®: {sbj}, å¸ç§: {ccy}, æ—¥æœŸ: {acg_dt}")

    if current_type == "type1":
        logging.info("\nã€é”™è¯¯åŸå› åˆ†æã€‘")
        logging.info("Type1 - æ’å®šå·®é¢é”™è¯¯ï¼š")
        logging.info("  6æœˆ1æ—¥èµ·æ€»è´¦æˆ·ä¸åˆ†æˆ·åˆè®¡å·®é¢æ’å®šï¼Œä¸šåŠ¡æœŸé—´åˆ†æˆ·/æ€»è´¦åŒæ­¥å˜åŠ¨ã€‚")
        logging.info("  å¯èƒ½åŸå› ï¼š")
        logging.info("    1. ç³»ç»Ÿæ€§çš„ä½™é¢è®¡ç®—é”™è¯¯")
        logging.info("    2. åˆå§‹ä½™é¢è®¾ç½®é—®é¢˜")
        logging.info("    3. ç§‘ç›®ä½™é¢ä¸åˆ†æˆ·ä½™é¢ä¹‹é—´å­˜åœ¨å›ºå®šåå·®")
        if record:
            logging.info(f"  æ’å®šå·®é¢å€¼: {record.get('tot_mint_dif', 'N/A')}")

    elif current_type == "type2":
        logging.info("\nã€é”™è¯¯åŸå› åˆ†æã€‘")
        logging.info("Type2 - å·®é¢å˜åŒ–é”™è¯¯ï¼š")
        logging.info(
            " 6æœˆ1æ—¥èµ·æ€»è´¦æˆ·ä¸åˆ†æˆ·åˆè®¡äº§ç”Ÿå·®é¢ä¸å›ºå®šï¼Œä¸šåŠ¡æœŸé—´åˆ†æˆ·/æ€»è´¦ä¸åŒæ­¥å˜åŠ¨ã€‚è¯¥æ€»åˆ†ä¸å¹³å‘ç”Ÿåœ¨6æœˆ1æ—¥ä¹‹å‰ï¼ŒåŒæ—¶ä¸­é—´åˆå‘ç”Ÿäº†æ–°çš„é”™è¯¯.")
        logging.info("  å¯èƒ½åŸå› ï¼š")
        logging.info("    1. åœ¨ç‰¹å®šæ—¥æœŸå‘ç”Ÿäº†äº¤æ˜“æˆ–è°ƒæ•´")
        logging.info("    2. ä¼ ç¥¨æ•°æ®ä¸åˆ†æˆ·ä½™é¢æ•°æ®åœ¨å˜åŒ–ç‚¹æ—¥æœŸä¸ä¸€è‡´")
        logging.info("    3. å¯èƒ½å­˜åœ¨æ•°æ®å½•å…¥é”™è¯¯æˆ–å†²æ­£æ“ä½œ")
        change_list = record.get('change_list', [])
        change_dates = record.get('change_dates', [])
        if change_list:
            logging.info(f"  å·®é¢å˜åŒ–åºåˆ—: {change_list}")
            logging.info(f"  å˜åŒ–æ—¥æœŸ: {change_dates}")

    elif current_type == "type3":
        logging.info("\nã€é”™è¯¯åŸå› åˆ†æã€‘")
        logging.info("Type3 - å·®é¢å½’é›¶é”™è¯¯ï¼š")
        logging.info("  è´¦æˆ·éƒ¨åˆ†å¤©æ•°æ€»åˆ†å¹³è¡¡ï¼Œéƒ¨åˆ†å¤©æ•°æ€»åˆ†ä¸å¹³ã€‚")
        logging.info("  å¯èƒ½åŸå› ï¼š")
        logging.info("    1. åœ¨æŸæ®µæ—¶é—´å†…å‘ç”Ÿäº†é”™è¯¯ï¼Œä¹‹åè¢«çº æ­£")
        logging.info("    2. å¯èƒ½å­˜åœ¨çº¢è“å­—å†²é”€æ“ä½œ")
        logging.info("    3. æ•°æ®åœ¨å¼‚å¸¸æœŸé—´åè‡ªåŠ¨å½’é›¶")
        zero_span = record.get('zero_span', {})
        if zero_span:
            logging.info(f"  å¼‚å¸¸æ—¥æœŸèŒƒå›´: {zero_span.get('start')} è‡³ {zero_span.get('end')}")
            red_blue_result = state.get("red_blue_cancellations", {})
            if current_type == "type3" and red_blue_result:
                summary = red_blue_result.get("summary", {})
                vouchers = red_blue_result.get("raw_vouchers", [])
                tot_records = red_blue_result.get("tot_records", [])
                match_result = red_blue_result.get("matches", [])
                logging.info("\nã€å†²é”€å‡­è¯åˆ†æã€‘")
                logging.info(f"  {summary.get('note', '')}")
                logging.info(f"  â†’ {summary.get('conclusion', '')}")
                logging.info("\nã€å†²é”€å«Œç–‘åŒ¹é…è¯¦æƒ…ã€‘")
                if not match_result:
                    logging.info("â†’ æœªå‘ç°å‡­è¯é‡‘é¢ä¸æ€»å·®å¼‚é«˜åº¦å»åˆçš„è®°å½•ã€‚")
                else:
                    for i, item in enumerate(match_result, 1):
                        v = item["voucher"]
                        t = item["tot_record"]
                        diff = item["abs_diff"]
                        rd_flag = "ğŸ”´ R" if v.get("rd_flg") == "R" else "ğŸ”µ B"
                        logging.info(f"{i:2d}. {rd_flag} å‡­è¯ {v['vchr_num']} | æ—¥æœŸ {v['dt']} | é‡‘é¢ {v['amt']:+.2f} "
                                     f"â‰ˆ å·®å¼‚ {t['dif']:+.2f} (å·®å€¼ {diff:.4f})")

    logging.info("\nã€éªŒè¯ç»“æœæ±‡æ€»ã€‘")
    logging.info("  Historyè¡¨(ä¼ ç¥¨å‘ç”Ÿé¢):")
    logging.info(f"    - è´¦æˆ·æ•°: {history.get('count', 0)}")
    logging.info(f"    - æ€»å€Ÿæ–¹: {history.get('total_debit', 0):.2f}")
    logging.info(f"    - æ€»è´·æ–¹: {history.get('total_credit', 0):.2f}")
    logging.info(f"    - æ€»å·®é¢: {history.get('total_diff', 0):.2f}")
    # logging.info(f"   - å¯ç–‘çš„è´¦å·: {per_account:.2f}")
    logging.info("  Individualè¡¨(åˆ†æˆ·ä½™é¢å·®):")
    logging.info(f"    - è´¦æˆ·æ•°: {individual.get('count', 0)}")
    logging.info(f"    - æ€»å·®é¢: {individual.get('total_diff', 0):.2f}")
    # æ·»åŠ å‰30ä¸ªä¸ä¸€è‡´çš„è´¦å·ä¿¡æ¯
    inconsistent_accounts = [r for r in per_account if not r["is_consistent"]]
    logging.info("  ä¼ ç¥¨å†å²è·Ÿåˆ†æˆ·å·®é¢ä¸ä¸€è‡´çš„è´¦å· (å‰30ä¸ª):")
    if per_account == []:
        logging.info(f"â†’ ä¼ ç¥¨å†å²è¡¨è·Ÿåˆ†æˆ·ä½™é¢è¡¨å…¶ä¸­ä¸€ä¸ªè¡¨å­˜åœ¨å¯¹åº”çš„{org}, {sbj}, {ccy}, {acg_dt}ä¸¢å¤±ï¼Œè¯·æ£€æŸ¥ã€‚")
    for i, account in enumerate(inconsistent_accounts[:30], start=1):
        logging.info(
            f"    [{i}] è´¦å·: {account['acct_num']}, å·®å¼‚: {account['difference']:.4f}, é”™è¯¯ç‡: {account['error_rate']:.6f}%,å€Ÿè´·å‘ç”Ÿé¢: {account['history_balance_diff']},åˆ†æˆ·å·®é¢: {account['individual_balance_diff']}")

    logging.info("-" * 80 + "\n")


def _validate_voucher_today(acg_dt: str, org_num: str, sbj_num: str, ccy_symb: str) -> Dict[str, Any]:
    sql = f"""
        SELECT
            t.acct_num,
            t.acg_org_num,
            t.sbj_num,
            t.ccy_symb,
            SUM(CASE
                    WHEN t.ldin_flg = 'D' AND (t.rd_flg IS NULL OR t.rd_flg = 'B') THEN CAST(t.amt AS DECIMAL(18,2))
                    WHEN t.ldin_flg = 'D' AND t.rd_flg = 'R' THEN -CAST(t.amt AS DECIMAL(18,2))
                    ELSE 0
                END) AS debit_amt,
            SUM(CASE
                    WHEN t.ldin_flg = 'C' AND (t.rd_flg IS NULL OR t.rd_flg = 'B') THEN CAST(t.amt AS DECIMAL(18,2))
                    WHEN t.ldin_flg = 'C' AND t.rd_flg = 'R' THEN -CAST(t.amt AS DECIMAL(18,2))
                    ELSE 0
                END) AS credit_amt,
            SUM(CASE
                    WHEN t.ldin_flg = 'D' AND (t.rd_flg IS NULL OR t.rd_flg = 'B') THEN CAST(t.amt AS DECIMAL(18,2))
                    WHEN t.ldin_flg = 'D' AND t.rd_flg = 'R' THEN -CAST(t.amt AS DECIMAL(18,2))
                    WHEN t.ldin_flg = 'C' AND (t.rd_flg IS NULL OR t.rd_flg = 'B') THEN -CAST(t.amt AS DECIMAL(18,2))
                    WHEN t.ldin_flg = 'C' AND t.rd_flg = 'R' THEN CAST(t.amt AS DECIMAL(18,2))
                    ELSE 0
                END) AS balance_diff
        FROM history_total t
        WHERE t.dt = '{acg_dt}'
          AND t.acg_org_num = '{org_num}'
          AND t.sbj_num = '{sbj_num}'
          AND t.ccy_symb = '{ccy_symb}'
        GROUP BY t.acct_num, t.acg_org_num, t.sbj_num, t.ccy_symb;
    """
    rows = execute_query_tool.invoke(sql)
    return {
        "count": len(rows),
        "total_debit": sum(r['debit_amt'] for r in rows),
        "total_credit": sum(r['credit_amt'] for r in rows),
        "total_diff": sum(r['balance_diff'] for r in rows),
        "records": rows,
        "summary_diff": sum(r['debit_amt'] for r in rows) - sum(r['credit_amt'] for r in rows),
    }


def _validate_ledger_day(acg_dt: str, org_num: str, sbj_num: str, ccy_int: str) -> Dict[str, Any]:
    # éœ€è¦ acg_dt+1
    acg_dt_after = (datetime.strptime(acg_dt, "%Y%m%d") + timedelta(days=1)).strftime("%Y%m%d")
    sql = f"""
        SELECT 
            a.acct_num,
            a.sbj_num,
            a.ccy,
            a.bal_prev_day,
            b.bal_curr_day,
            b.bal_curr_day - a.bal_prev_day AS balance_diff
        FROM (
            SELECT acct_num, sbj_num, ccy, CAST(sbact_acct_bal AS DECIMAL(18,2)) AS bal_prev_day
            FROM individual_total
            WHERE dt = '{acg_dt}' 
              AND org_num = '{org_num}'
              AND sbj_num = '{sbj_num}'
              AND ccy = '{ccy_int}'
        ) a
        JOIN (
            SELECT acct_num, sbj_num, ccy, CAST(sbact_acct_bal AS DECIMAL(18,2)) AS bal_curr_day
            FROM individual_total
            WHERE dt = '{acg_dt_after}' 
              AND org_num = '{org_num}'
              AND sbj_num = '{sbj_num}'
              AND ccy = '{ccy_int}'
        ) b ON a.acct_num = b.acct_num 
           AND a.sbj_num = b.sbj_num 
           AND a.ccy = b.ccy;
    """
    rows = execute_query_tool.invoke(sql)
    return {
        "count": len(rows),
        "records": rows,
        "total_diff": sum(r['balance_diff'] for r in rows),
    }


def _compare_account_diffs(history_rows: List[Dict[str, Any]], individual_rows: List[Dict[str, Any]]) -> List[
    Dict[str, Any]]:
    history = {r['acct_num']: float(r['balance_diff']) for r in history_rows}
    individual = {r['acct_num']: float(r['balance_diff']) for r in individual_rows}
    common = sorted(set(history) & set(individual))
    out = []
    for acct in common:
        h = abs(history[acct])
        i = abs(individual[acct])
        diff = h - i
        out.append({
            "acct_num": acct,
            "history_balance_diff": h,
            "individual_balance_diff": i,
            "difference": diff,
            "is_consistent": abs(diff) < 0.01,
            "error_rate": abs(diff / h * 100) if h != 0 else 0,
        })
    return out


from datetime import datetime
from typing import List, Dict, Any


def _check_red_blue_cancellation_in_type3(
        org_num: str,
        sbj_num: str,
        ccy_symb: str,
        start_dt: str,
        end_dt: str,
) -> dict[str, dict[str, str | int | float] | list[Any] | int | Any]:
    """ç²¾å‡†åŒ¹é…æ¨¡å¼ï¼šä»…æ¯”å¯¹ tot.dif ä¸ voucher.amt æ˜¯å¦ç›¸ç­‰ï¼ˆå®¹å·® Â±0.001ï¼‰ï¼Œè¿”å›æ‰€æœ‰åŒ¹é…é¡¹"""
    if not all([org_num, sbj_num, ccy_symb, start_dt, end_dt]):
        raise ValueError("æ‰€æœ‰å‚æ•°å¿…é¡»æä¾›")

    try:
        datetime.strptime(start_dt, "%Y%m%d")
        datetime.strptime(end_dt, "%Y%m%d")
    except ValueError:
        raise ValueError("æ—¥æœŸæ ¼å¼å¿…é¡»ä¸º YYYYMMDD")

    # === Step 1: æŸ¥è¯¢ zero_span æœŸé—´å†…æ‰€æœ‰å‡­è¯ï¼ˆä»…éœ€ amt + åŸºç¡€å­—æ®µï¼‰===
    sql_vchr = f"""
        SELECT 
            vchr_num,
            dt,
            ldin_flg,
            rd_flg,
            CAST(amt AS DECIMAL(18,2)) AS amt
        FROM history_total
        WHERE acg_org_num = '{org_num}'
          AND sbj_num = '{sbj_num}'
          AND ccy_symb = '{ccy_symb}'
          AND dt BETWEEN '{start_dt}' AND '{end_dt}'
          AND vchr_num IS NOT NULL
        ORDER BY acg_dt, vchr_num;
    """
    raw_vouchers = execute_query_tool.invoke(sql_vchr)

    # === Step 2: æŸ¥è¯¢ tot è¡¨ dif è®°å½•ï¼ˆä»…éœ€ dt + difï¼‰===
    sql_tot = f"""
        SELECT 
            dt,
            CAST(tot_mint_dif AS DECIMAL(18,2)) AS dif
        FROM tot
        WHERE org_num = '{org_num}'
          AND sbj_num = '{sbj_num}'
          AND ccy = '{ccy_symb}'
          AND dt BETWEEN '{start_dt}' AND '{end_dt}'
        ORDER BY dt;
    """
    tot_records = execute_query_tool.invoke(sql_tot)

    # === Step 3: ä¸¤ä¸¤æ¯”å¯¹ amt ä¸ difï¼Œè¯¯å·® < 0.001 è§†ä¸ºåŒ¹é… ===
    matches = []
    TOLERANCE = 0.001

    for v in raw_vouchers:
        v_amt = float(v["amt"])
        for t in tot_records:
            t_dif = float(t["dif"])
            if abs(v_amt - t_dif) < TOLERANCE:
                matches.append({
                    "voucher": v,
                    "tot_record": t,
                    "abs_diff": abs(v_amt - t_dif)
                })

    # === Step 4: æ„å»ºè¿”å›ç»“æœ ===
    summary = {
        "note": f"ã€å†²é”€å«Œç–‘åŒ¹é…åˆ†æã€‘æœŸé—´ {start_dt}â€“{end_dt}ï¼š"
                f"å…± {len(raw_vouchers)} ç¬”å‡­è¯ï¼Œ{len(tot_records)} æ¡å·®å¼‚è®°å½•ï¼›"
                f"å‘ç° {len(matches)} ç»„å‡­è¯é‡‘é¢ä¸å½“æ—¥æ€»å·®å¼‚é«˜åº¦å»åˆï¼ˆè¯¯å·® < {TOLERANCE}ï¼‰ã€‚",
        "match_count": len(matches),
        "tolerance_used": TOLERANCE,
        "interpretation": (
            "âš ï¸ æ³¨æ„ï¼šæ­¤ç±»ç²¾ç¡®åŒ¹é…å¸¸è§äºçº¢å­—å†²é”€ï¼ˆRï¼‰æˆ–è“å­—åå‘å‡­è¯æ“ä½œï¼Œ"
            "å¯èƒ½å¯¼è‡´å•æ—¥å‡­è¯é‡‘é¢ç›´æ¥ä½“ç°ä¸º tot_mint_difã€‚"
            "å»ºè®®äººå·¥æ ¸æŸ¥åŒ¹é…é¡¹ä¸­çš„ rd_flg='R' æˆ–å¼‚å¸¸å€Ÿè´·æ–¹å‘å‡­è¯ã€‚"
        )
    }

    return {
        "summary": summary,
        "matches": matches,  # æŒ‰ amt â‰ˆ dif åŒ¹é…æˆåŠŸçš„å¯ç–‘å†²é”€å€™é€‰
        "raw_vouchers": raw_vouchers,
        "tot_records": tot_records,
        "suspicious_candidates": len([m for m in matches if m["voucher"].get("rd_flg") == "R"]),
    }


# -------- Nodes --------
def node_scan(state: AgentState) -> AgentState:
    sql = """
        SELECT 
                org_num, 
                sbj_num, 
                ccy, 
                sbact_acct_bal,
                gnl_ldgr_bal,
                tot_mint_dif,
                dt 
        FROM tot 
        WHERE CAST(NULLIF(tot_mint_dif, '') AS NUMERIC(18,2)) != 0.00
        ORDER BY  org_num, sbj_num, ccy,dt;
    """
    records = execute_query_tool.invoke(sql)
    state["discrepancies"] = records
    state["classes"] = classify_errors(records)

    # æ‰“å°åˆ†ç±»åˆ†æç»“æœ
    _print_classification_analysis(state["classes"], records)

    # åˆå§‹åŒ–ç´¢å¼•ï¼šæŒ‰ä¼˜å…ˆçº§ type1 -> type2 -> type3
    state["current_type_index"] = {"type1": 0, "type2": 0, "type3": 0}
    state["current_date_index"] = 0
    state["results"] = []
    state["has_more"] = True  # åˆå§‹åŒ–ä¸º Trueï¼Œè¡¨ç¤ºæœ‰è®°å½•éœ€è¦å¤„ç†
    return state


def node_pick_next(state: AgentState) -> AgentState:
    """
    ä» classes ä¸­æŒ‰ä¼˜å…ˆçº§é€‰æ‹©ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„è®°å½•å’Œæ—¥æœŸ
    é»˜è®¤ä¼˜å…ˆçº§ï¼štype3 -> type1 -> type2
    å¯¹äº type2ï¼Œéœ€è¦éå† change_dates ä¸­çš„æ‰€æœ‰æ—¥æœŸ
    """
    classes = state.get("classes", {})
    type_index = state.get("current_type_index", {"type1": 0, "type2": 0, "type3": 0})

    # ä¼˜å…ˆçº§é¡ºåº
    type_order = ["type3", "type1", "type2"]

    for type_name in type_order:
        type_records = classes.get(type_name, [])
        if not type_records:
            continue

        idx = type_index.get(type_name, 0)
        if idx >= len(type_records):
            continue  # è¿™ä¸ªç±»å‹å·²ç»å¤„ç†å®Œï¼Œç»§ç»­ä¸‹ä¸€ä¸ªç±»å‹

        record = type_records[idx]
        org = record["org_num"]
        sbj = record["sbj_num"]
        ccy = record["ccy"]

        # æ ¹æ®ç±»å‹å†³å®šå¤„ç†å“ªäº›æ—¥æœŸ
        if type_name == "type1":
            # type1: æ’å®šå·®é¢ï¼Œå¤„ç†ç¬¬ä¸€ä¸ªæ—¥æœŸå³å¯
            dt = record["dt"]
            state["current_record"] = record
            state["current_target"] = (org, sbj, ccy, dt)
            state["current_type"] = type_name
            # å¤„ç†å®Œè¿™æ¡è®°å½•ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€æ¡
            type_index[type_name] = idx + 1
            state["current_type_index"] = type_index
            state["has_more"] = True  # æ ‡è®°è¿˜æœ‰æ›´å¤šè®°å½•
            return state

        elif type_name == "type2":
            # type2: æœ‰å¤šä¸ªå˜åŒ–ç‚¹ï¼Œéœ€è¦å¤„ç† change_dates ä¸­çš„æ¯ä¸ªæ—¥æœŸ
            change_dates = record.get("change_dates", [])
            if not change_dates:
                # å¦‚æœæ²¡æœ‰ change_datesï¼Œä½¿ç”¨ dt
                dt = record["dt"]
                state["current_record"] = record
                state["current_target"] = (org, sbj, ccy, dt)
                state["current_type"] = type_name
                type_index[type_name] = idx + 1
                state["current_date_index"] = 0
                state["current_type_index"] = type_index
                state["has_more"] = True
                return state

            # è·å–å½“å‰è®°å½•çš„æ—¥æœŸç´¢å¼•ï¼ˆå¦‚æœå½“å‰è®°å½•ä¸æ˜¯è¿™æ¡ï¼Œé‡ç½®ä¸º0ï¼‰
            current_record_key = f"{org}|{sbj}|{ccy}"
            last_record = state.get("current_record", {})
            last_record_key = f"{last_record.get('org_num', '')}|{last_record.get('sbj_num', '')}|{last_record.get('ccy', '')}"

            if current_record_key != last_record_key:
                # åˆ‡æ¢åˆ°æ–°è®°å½•ï¼Œé‡ç½®æ—¥æœŸç´¢å¼•
                state["current_date_index"] = 0

            date_idx = state.get("current_date_index", 0)
            if date_idx < len(change_dates):
                # è¿˜æœ‰æ—¥æœŸæœªå¤„ç†
                dt = change_dates[date_idx]
                state["current_record"] = record
                state["current_target"] = (org, sbj, ccy, dt)
                state["current_type"] = type_name
                state["current_date_index"] = date_idx + 1
                state["current_type_index"] = type_index
                state["has_more"] = True
                return state
            else:
                # è¿™ä¸ªè®°å½•çš„æ‰€æœ‰æ—¥æœŸéƒ½å¤„ç†å®Œäº†ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€æ¡è®°å½•
                type_index[type_name] = idx + 1
                state["current_date_index"] = 0
                state["current_type_index"] = type_index
                # ç»§ç»­å¾ªç¯ï¼Œå¤„ç†ä¸‹ä¸€æ¡è®°å½•
                continue

        elif type_name == "type3":
            # type3: å¤„ç† zero_span ä¸­çš„æ—¥æœŸèŒƒå›´
            zero_span = record.get("zero_span", {})
            if zero_span:
                # å¯ä»¥å¤„ç† span çš„ start å’Œ endï¼Œæˆ–è€…æ•´ä¸ªèŒƒå›´
                # è¿™é‡Œå…ˆå¤„ç† start æ—¥æœŸ
                dt = zero_span.get("start", record["dt"])
            else:
                dt = record["dt"]

            state["current_record"] = record
            state["current_target"] = (org, sbj, ccy, dt)
            state["current_type"] = type_name
            type_index[type_name] = idx + 1
            state["current_type_index"] = type_index
            state["has_more"] = True
            return state

    # æ‰€æœ‰ç±»å‹éƒ½å¤„ç†å®Œäº†
    state["has_more"] = False
    # å¦‚æœæ²¡æœ‰æ›´å¤šè®°å½•ï¼Œä¹Ÿè¦ç¡®ä¿ current_target å­˜åœ¨ï¼ˆé¿å… validate èŠ‚ç‚¹æŠ¥é”™ï¼‰
    if "current_target" not in state or state.get("current_target") is None:
        # å¦‚æœæ²¡æœ‰ä»»ä½•è®°å½•ï¼Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å€¼ï¼ˆè™½ç„¶ä¸åº”è¯¥å‘ç”Ÿï¼‰
        state["current_target"] = ("", "", "", "")
    return state


def node_decide(state: AgentState) -> str:
    """
    åˆ¤æ–­æ˜¯å¦è¿˜æœ‰éœ€è¦å¤„ç†çš„è®°å½•
    """
    # ç›´æ¥æ£€æŸ¥ has_more æ ‡å¿—
    if not state.get("has_more", False):
        return "finish"
    return "next"


def node_validate(state: AgentState) -> AgentState:
    org, sbj, ccy_symb, acg_dt = state["current_target"]

    ccy_mapping = load_ccy_mapping()
    ccy_int = ccy_mapping.get(ccy_symb)
    if not ccy_int:
        raise ValueError(f"æ— æ•ˆçš„å¸ç§ç¬¦å·: {ccy_symb}")

    history = _validate_voucher_today(acg_dt, org, sbj, ccy_symb)
    individual = _validate_ledger_day(acg_dt, org, sbj, ccy_int)
    state["history"] = history
    state["individual"] = individual
    return state


def node_compare(state: AgentState) -> AgentState:
    per = _compare_account_diffs(state["history"]["records"], state["individual"]["records"])
    state["per_account"] = per
    inc = [r for r in per if not r["is_consistent"]]
    org, sbj, ccy, acg_dt = state["current_target"]

    # æ·»åŠ ç±»å‹ä¿¡æ¯å’Œåˆ†ç±»è®°å½•ä¸­çš„é¢å¤–ä¿¡æ¯
    result = {
        "org_num": org,
        "sbj_num": sbj,
        "ccy": ccy,
        "acg_dt": acg_dt,
        "type": state.get("current_type", "unknown"),
        "history_total_diff": state["history"]["total_diff"],
        "individual_total_diff": state["individual"]["total_diff"],
        "account_inconsistent_count": len(inc),
        "inconsistent_accounts": inc[:50],
    }

    # æ ¹æ®ç±»å‹æ·»åŠ é¢å¤–ä¿¡æ¯
    record = state.get("current_record", {})
    if state.get("current_type") == "type2":
        result["change_list"] = record.get("change_list", [])
        result["change_dates"] = record.get("change_dates", [])
    elif state.get("current_type") == "type3":
        result["zero_span"] = record.get("zero_span", {})
        # å¯¹äºtype3ç±»å‹ï¼Œæ‰§è¡Œå†²é”€å‡­è¯æ£€æŸ¥
        zero_span = record.get("zero_span", {})
        if zero_span:
            start_dt = zero_span.get("start", acg_dt)
            end_dt = zero_span.get("end", acg_dt)
            red_blue_cancellations = _check_red_blue_cancellation_in_type3(
                org, sbj, ccy, start_dt, end_dt
            )
            state["red_blue_cancellations"] = red_blue_cancellations
            result["red_blue_cancellations"] = red_blue_cancellations

    state["results"].append(result)

    # æ‰“å°æ¯ä¸ªè´¦æˆ·å¤„ç†å®Œæˆåçš„ç»“æœ
    _print_account_result(state)

    return state


def node_finish(state: AgentState) -> AgentState:
    total_discrepancies = len(state.get("discrepancies", []))
    state["summary"] = {
        "total_discrepancies": total_discrepancies,
        "group_count": len(state.get("results", [])),
        "type1": len(state.get("classes", {}).get("type1", [])),
        "type2": len(state.get("classes", {}).get("type2", [])),
        "type3": len(state.get("classes", {}).get("type3", [])),
    }
    return state


# -------- Graph builder --------
def build_graph():
    g = StateGraph(AgentState)
    g.add_node("scan", node_scan)
    g.add_node("pick_next", node_pick_next)
    g.add_node("validate", node_validate)
    g.add_node("compare", node_compare)
    g.add_node("finish", node_finish)

    g.set_entry_point("scan")
    g.add_edge("scan", "pick_next")
    g.add_edge("pick_next", "validate")
    g.add_edge("validate", "compare")
    g.add_conditional_edges("compare", node_decide, {
        "finish": "finish",
        "next": "pick_next",
    })

    return g.compile()


# -------- Public API --------
def run_react() -> Dict[str, Any]:
    app = build_graph()
    final = app.invoke({}, config={"recursion_limit": 100})
    # âœ… æŠ•å½±ï¼šä»…ä¿ç•™ä¸»æ™ºèƒ½ä½“éœ€è¦çš„å­—æ®µ
    output: OutputState = {
        "discrepancies": final.get("discrepancies", []),
        "classes": final.get("classes", {}),
        "results": final.get("results", []),
        "summary": final.get("summary", {}),
    }
    return output


if __name__ == "__main__":
    import json

    try:
        result = run_react()
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(f"æ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
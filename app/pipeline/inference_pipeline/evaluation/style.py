import json
from typing import Any

from app.configs import agent_config as settings
from langfuse import openai
from pydantic import BaseModel

from .metrics import EvaluationMetric, ScoreResult


class LLMJudgeStyleOutputResult(BaseModel):
    score: int
    reason: str


class Style(EvaluationMetric):
    """
    Judge whether an answer uses an approachable tone that is suitable for blogs or social media content.

    The metric uses an auxiliary LLM call through Langfuse. Scores are normalized to a 0..1 range.
    """

    def __init__(
        self,
        name: str = "style_metric",
        model_name: str = settings.OPENAI_MODEL_ID,
    ) -> None:
        self.name = name
        self.llm_client = openai(model_name=model_name)
        self.prompt_template = """
You are an impartial expert judge. Evaluate the quality of a given answer to an instruction based on its style.
Is the tone appropriate for a blog or social media post? The answer should be concise, technically precise, and avoid formal or academic tone.

Style scale:
1 (Poor): Too formal or overly complex wording.
2 (Good): Understandable but still has formal expressions.
3 (Excellent): Conversational, clear, and precise.

Instruction: {input}
Answer: {output}

Respond strictly as JSON with keys "score" (integer from 1 to 3) and "reason" (short explanation).
"""# noqa: E501

    def score(
        self,
        *,
        instruction: str,
        output: str,
        **ignored_kwargs: Any,
    ) -> ScoreResult:
        """
        Score the output of an LLM.

        Args:
            instruction: The user instruction that triggered the answer.
            output: The answer generated by the inference pipeline.
        """

        prompt = self.prompt_template.format(input=instruction, output=output)

        model_output = self.llm_client.generate_string(
            input=prompt,
            response_format=LLMJudgeStyleOutputResult,
        )

        return self._parse_model_output(model_output)

    def _parse_model_output(
        self,
        content: str | LLMJudgeStyleOutputResult,
    ) -> ScoreResult:
        if isinstance(content, LLMJudgeStyleOutputResult):
            parsed = content
        else:
            try:
                dict_content = json.loads(content)
                parsed = LLMJudgeStyleOutputResult(**dict_content)
            except Exception as exc:  # pragma: no cover - defensive branch
                return ScoreResult(
                    name=self.name,
                    value=0.0,
                    reason=f"Failed to parse style model output: {exc}",
                )

        score = max(1, min(3, parsed.score))
        normalized_score = (score - 1) / 2.0

        return ScoreResult(
            name=self.name,
            value=normalized_score,
            reason=parsed.reason,
        )
